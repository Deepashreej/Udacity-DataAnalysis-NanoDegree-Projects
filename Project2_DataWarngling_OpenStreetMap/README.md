### Overview:

Downloaded a dataset from MapZen and used data wrangling techniques to assess the quality of the data and make improvements where necessary. 

This project demonstrates the following steps:

- Assess the quality of the data for validity, accuracy, completeness, consistency and
    uniformity
- Parse and gather data from popular file formats such as .json, .xml, .csv, .html
- Process data from many files and very large files that can be cleaned with spreadsheet
    programs
- Learn how to store, query, and aggregate data using SQL
    
#### Setup:
This project has the following dependencies:
- Python 2.7
- Jupyter Notebook
- SQL Lite

Assuming that the data has been downloaded to the project root directory and been uncompressed, the IPython Notebook needs to be updated to set the OSM_FILE = "san-diego_california.osm".

In order to improve performance, a sample of the OSM data can be generated by running Python codes.ipynb in your Jupyter terminal from the project root. It is worth noting that, by default, the sampler is set up to generate a 10% sample (SAMPLE_FILE = "sample.osm") of the OSM data. OSM file name is hard coded within that script.

Running the file, *Python codes.ipynb* will also create the following .CSV files from the OSM data:
- nodes_file
- nodes_tags_file
- ways_file
- way_nodes_file
- way_tags_file

Running the file, *SQL.ipynb* will create and load the data from the above files to their respective SQL tables.
The data was then analyzed in SQL to discover further insights.






    
    


